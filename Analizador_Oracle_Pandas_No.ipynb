{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d01d7238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1: Importar librerías\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import chardet\n",
    "import numpy as np\n",
    "from IPython.display import display, Markdown  # Para mejor visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e94b70af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2: Función de detección de codificación\n",
    "def detectar_codificacion(ruta_archivo, muestra_bytes=10000):\n",
    "    \"\"\"Detecta la codificación del archivo de manera más confiable usando chardet.\"\"\"\n",
    "    with open(ruta_archivo, 'rb') as f:\n",
    "        resultado = chardet.detect(f.read(muestra_bytes))\n",
    "    return resultado['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "979bd833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3: Función para inferir tipos Oracle\n",
    "def inferir_tipo_oracle(serie):\n",
    "    \"\"\"Infiere el tipo de dato Oracle para una columna de pandas.\"\"\"\n",
    "    # Convertir a string si hay valores no string\n",
    "    if serie.dtype == object:\n",
    "        serie = serie.astype(str)\n",
    "    \n",
    "    # Intentar convertir a datetime\n",
    "    try:\n",
    "        datetime_serie = pd.to_datetime(serie, errors='coerce')\n",
    "        if not datetime_serie.isna().all():\n",
    "            if any(datetime_serie.dropna().apply(lambda x: x.time() != pd.Timestamp('00:00:00').time())):\n",
    "                return \"TIMESTAMP\"\n",
    "            else:\n",
    "                return \"DATE\"\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Intentar convertir a numérico\n",
    "    try:\n",
    "        numeric_serie = pd.to_numeric(serie, errors='coerce')\n",
    "        if not numeric_serie.isna().all():\n",
    "            if (numeric_serie.dropna() % 1 == 0).all():\n",
    "                max_val = numeric_serie.max()\n",
    "                min_val = numeric_serie.min()\n",
    "                if max_val < 10**10 and min_val > -10**10:\n",
    "                    return \"NUMBER(10)\"\n",
    "                else:\n",
    "                    return \"NUMBER(20)\"\n",
    "            else:\n",
    "                return \"NUMBER(15,2)\"\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    max_len = serie.str.len().max()\n",
    "    return f\"VARCHAR2({int(max_len)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff0458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4: Función de análisis principal\n",
    "def analizar_archivo_pandas(ruta_archivo):\n",
    "    \"\"\"Analiza completamente el archivo usando pandas.\"\"\"\n",
    "    display(Markdown(\"### Iniciando análisis con pandas...\"))\n",
    "    \n",
    "    # Detectar codificación\n",
    "    encoding = detectar_codificacion(ruta_archivo)\n",
    "    display(Markdown(f\"**Codificación detectada:** `{encoding}`\"))\n",
    "    \n",
    "    # Determinar si el archivo es grande\n",
    "    file_size = os.path.getsize(ruta_archivo)\n",
    "    es_grande = file_size > 100 * 1024 * 1024  # > 100MB\n",
    "    \n",
    "    if es_grande:\n",
    "        display(Markdown(\"**Archivo grande detectado.** Usando muestreo y lectura por chunks...\"))\n",
    "        \n",
    "        # Leer encabezados\n",
    "        reader = pd.read_csv(ruta_archivo, sep='|', quotechar='\"', \n",
    "                           encoding=encoding, nrows=0)\n",
    "        columnas = reader.columns.tolist()\n",
    "        \n",
    "        tipos_finales = {col: set() for col in columnas}\n",
    "        max_longitudes = {col: 0 for col in columnas}\n",
    "        total_filas = 0\n",
    "        \n",
    "        # Leer por chunks con barra de progreso\n",
    "        chunksize = 10**5\n",
    "        for chunk in tqdm(pd.read_csv(ruta_archivo, sep='|', quotechar='\"', \n",
    "                                     encoding=encoding, chunksize=chunksize,\n",
    "                                     low_memory=False, on_bad_lines='warn'),\n",
    "                          desc=\"Procesando chunks\"):\n",
    "            total_filas += len(chunk)\n",
    "            \n",
    "            for col in columnas:\n",
    "                col_limpia = col.strip().strip('\"')\n",
    "                serie = chunk[col].astype(str)\n",
    "                current_max = serie.str.len().max()\n",
    "                if current_max > max_longitudes[col_limpia]:\n",
    "                    max_longitudes[col_limpia] = current_max\n",
    "                tipo = inferir_tipo_oracle(serie)\n",
    "                tipos_finales[col_limpia].add(tipo)\n",
    "        \n",
    "        display(Markdown(f\"\\n**Total de filas procesadas:** `{total_filas:,}`\"))\n",
    "    else:\n",
    "        display(Markdown(\"**Archivo pequeño detectado.** Leyendo todo en memoria...\"))\n",
    "        df = pd.read_csv(ruta_archivo, sep='|', quotechar='\"', \n",
    "                         encoding=encoding, low_memory=False, \n",
    "                         on_bad_lines='warn')\n",
    "        \n",
    "        columnas = df.columns.tolist()\n",
    "        tipos_finales = {}\n",
    "        max_longitudes = {}\n",
    "        \n",
    "        for col in columnas:\n",
    "            col_limpia = col.strip().strip('\"')\n",
    "            serie = df[col].astype(str)\n",
    "            max_longitudes[col_limpia] = serie.str.len().max()\n",
    "            tipos_finales[col_limpia] = {inferir_tipo_oracle(serie)}\n",
    "    \n",
    "    # Consolidar tipos\n",
    "    tipos_consolidados = {}\n",
    "    for col, tipos in tipos_finales.items():\n",
    "        if len(tipos) == 1:\n",
    "            tipos_consolidados[col] = tipos.pop()\n",
    "        else:\n",
    "            if 'TIMESTAMP' in tipos:\n",
    "                tipos_consolidados[col] = 'TIMESTAMP'\n",
    "            elif 'DATE' in tipos:\n",
    "                tipos_consolidados[col] = 'DATE'\n",
    "            elif any(t.startswith('NUMBER') for t in tipos):\n",
    "                has_decimal = any('NUMBER(15,2)' in t for t in tipos)\n",
    "                tipos_consolidados[col] = 'NUMBER(15,2)' if has_decimal else 'NUMBER(10)'\n",
    "            else:\n",
    "                max_len = max(int(t.split('(')[1].split(')')[0]) for t in tipos if t.startswith('VARCHAR'))\n",
    "                tipos_consolidados[col] = f'VARCHAR2({max_len})'\n",
    "    \n",
    "    return max_longitudes, tipos_consolidados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac961f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5: Función para generar estructura Oracle\n",
    "def generar_estructura_oracle(nombre_tabla, max_longitudes, tipos_dato):\n",
    "    \"\"\"Genera la estructura Oracle optimizada con formato Markdown.\"\"\"\n",
    "    estructura = [f\"# ESTRUCTURA ORACLE GENERADA\\n```sql\\nCREATE TABLE {nombre_tabla.upper()} (\"]\n",
    "    \n",
    "    for campo in sorted(max_longitudes.keys()):\n",
    "        tipo = tipos_dato[campo]\n",
    "        nombre_col = campo[:30].upper()\n",
    "        estructura.append(f\"    {nombre_col.ljust(30)} {tipo},\")\n",
    "    \n",
    "    estructura[-1] = estructura[-1].rstrip(',')\n",
    "    estructura.append(\");\\n```\")\n",
    "    \n",
    "    return \"\\n\".join(estructura)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771a8be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Analizador de Archivos para Oracle"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7285f119602d44c8ba6d0e0a3b668d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Ruta:', placeholder='Introduce la ruta del archivo')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950df659995f44d5a04a075e9ab36327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='usuarios', description='Tabla:', placeholder='Nombre de tabla')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345f63392c6a41c98257f4c9c0ac9d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Analizar Archivo', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Resultados del Análisis"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Iniciando análisis con pandas..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Codificación detectada:** `ISO-8859-1`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Archivo grande detectado.** Usando muestreo y lectura por chunks..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 6: Interfaz de usuario con widgets (opcional pero recomendado)\n",
    "from ipywidgets import interact, widgets\n",
    "\n",
    "def interfaz_analizador():\n",
    "    display(Markdown(\"# Analizador de Archivos para Oracle\"))\n",
    "    \n",
    "    # Widgets de entrada\n",
    "    ruta = widgets.Text(\n",
    "        value='',\n",
    "        placeholder='Introduce la ruta del archivo',\n",
    "        description='Ruta:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    nombre_tabla = widgets.Text(\n",
    "        value='usuarios',\n",
    "        placeholder='Nombre de tabla',\n",
    "        description='Tabla:',\n",
    "        disabled=False\n",
    "    )\n",
    "    \n",
    "    display(ruta, nombre_tabla)\n",
    "    \n",
    "    def on_button_click(b):\n",
    "        display(Markdown(\"## Resultados del Análisis\"))\n",
    "        try:\n",
    "            max_len, tipos = analizar_archivo_pandas(ruta.value)\n",
    "            \n",
    "            if max_len and tipos:\n",
    "                display(Markdown(\"### Resumen de Columnas\"))\n",
    "                resumen = pd.DataFrame({\n",
    "                    'Columna': list(max_len.keys()),\n",
    "                    'Long. Máx': list(max_len.values()),\n",
    "                    'Tipo Oracle': list(tipos.values())\n",
    "                })\n",
    "                display(resumen)\n",
    "                \n",
    "                estructura = generar_estructura_oracle(nombre_tabla.value, max_len, tipos)\n",
    "                display(Markdown(\"### Estructura SQL Generada\"))\n",
    "                display(Markdown(estructura))\n",
    "        except Exception as e:\n",
    "            display(Markdown(f\"**Error:** `{str(e)}`\"))\n",
    "    \n",
    "    button = widgets.Button(description=\"Analizar Archivo\")\n",
    "    button.on_click(on_button_click)\n",
    "    display(button)\n",
    "\n",
    "# Ejecutar la interfaz\n",
    "interfaz_analizador()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
